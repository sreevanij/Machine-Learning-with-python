{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Text Classification with Tensor Flow\n",
    "We use IMDB data to predict the reveiws to be positive or negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "data = keras.datasets.imdb\n",
    "\n",
    "(train_data,train_labels),(test_data,test_labels) = data.load_data(num_words=10000)\n",
    "word_index = data.get_word_index()\n",
    "word_index = {k:(v+3) for k,v in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] =1\n",
    "word_index[\"<UNK>\"]=2\n",
    "word_index[\"<UNUSED>\"]=3\n",
    "reverse_word_index = dict([(value,key) for (key,value) in word_index.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = keras.preprocessing.sequence.pad_sequences(train_data,value=word_index[\"<PAD>\"], padding=\"post\", maxlen=250)\n",
    "test_data = keras.preprocessing.sequence.pad_sequences(test_data,value=word_index[\"<PAD>\"], padding=\"post\", maxlen=250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_review(text):\n",
    "    return \" \".join([reverse_word_index].get(i,\"?\") for i in text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(10000,16))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(16,activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(1,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 160,289\n",
      "Trainable params: 160,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "15000/15000 [==============================] - 1s 83us/sample - loss: 0.0899 - accuracy: 0.9785 - val_loss: 0.3170 - val_accuracy: 0.8807\n",
      "Epoch 2/40\n",
      "15000/15000 [==============================] - 0s 30us/sample - loss: 0.0853 - accuracy: 0.9805 - val_loss: 0.3180 - val_accuracy: 0.8837\n",
      "Epoch 3/40\n",
      "15000/15000 [==============================] - 0s 29us/sample - loss: 0.0812 - accuracy: 0.9815 - val_loss: 0.3230 - val_accuracy: 0.8820\n",
      "Epoch 4/40\n",
      "15000/15000 [==============================] - 0s 30us/sample - loss: 0.0778 - accuracy: 0.9827 - val_loss: 0.3279 - val_accuracy: 0.8818\n",
      "Epoch 5/40\n",
      "15000/15000 [==============================] - 0s 30us/sample - loss: 0.0744 - accuracy: 0.9836 - val_loss: 0.3334 - val_accuracy: 0.8811\n",
      "Epoch 6/40\n",
      "15000/15000 [==============================] - 0s 30us/sample - loss: 0.0712 - accuracy: 0.9845 - val_loss: 0.3390 - val_accuracy: 0.8803\n",
      "Epoch 7/40\n",
      "15000/15000 [==============================] - 0s 30us/sample - loss: 0.0684 - accuracy: 0.9852 - val_loss: 0.3468 - val_accuracy: 0.8787\n",
      "Epoch 8/40\n",
      "15000/15000 [==============================] - 1s 38us/sample - loss: 0.0654 - accuracy: 0.9859 - val_loss: 0.3503 - val_accuracy: 0.8786\n",
      "Epoch 9/40\n",
      "15000/15000 [==============================] - 1s 35us/sample - loss: 0.0635 - accuracy: 0.9870 - val_loss: 0.3595 - val_accuracy: 0.8780\n",
      "Epoch 10/40\n",
      "15000/15000 [==============================] - 0s 32us/sample - loss: 0.0607 - accuracy: 0.9881 - val_loss: 0.3633 - val_accuracy: 0.8785\n",
      "Epoch 11/40\n",
      "15000/15000 [==============================] - 1s 38us/sample - loss: 0.0576 - accuracy: 0.9885 - val_loss: 0.3683 - val_accuracy: 0.8782\n",
      "Epoch 12/40\n",
      "15000/15000 [==============================] - 1s 41us/sample - loss: 0.0554 - accuracy: 0.9889 - val_loss: 0.3741 - val_accuracy: 0.8771\n",
      "Epoch 13/40\n",
      "15000/15000 [==============================] - 1s 36us/sample - loss: 0.0533 - accuracy: 0.9895 - val_loss: 0.3813 - val_accuracy: 0.8764\n",
      "Epoch 14/40\n",
      "15000/15000 [==============================] - 0s 32us/sample - loss: 0.0510 - accuracy: 0.9906 - val_loss: 0.3846 - val_accuracy: 0.8770\n",
      "Epoch 15/40\n",
      "15000/15000 [==============================] - 0s 31us/sample - loss: 0.0492 - accuracy: 0.9911 - val_loss: 0.3913 - val_accuracy: 0.8760\n",
      "Epoch 16/40\n",
      "15000/15000 [==============================] - 0s 32us/sample - loss: 0.0477 - accuracy: 0.9915 - val_loss: 0.4013 - val_accuracy: 0.8764\n",
      "Epoch 17/40\n",
      "15000/15000 [==============================] - 0s 31us/sample - loss: 0.0451 - accuracy: 0.9923 - val_loss: 0.4050 - val_accuracy: 0.8753\n",
      "Epoch 18/40\n",
      "15000/15000 [==============================] - 0s 30us/sample - loss: 0.0436 - accuracy: 0.9925 - val_loss: 0.4129 - val_accuracy: 0.8749\n",
      "Epoch 19/40\n",
      "15000/15000 [==============================] - 1s 36us/sample - loss: 0.0418 - accuracy: 0.9927 - val_loss: 0.4164 - val_accuracy: 0.8753\n",
      "Epoch 20/40\n",
      "15000/15000 [==============================] - 0s 31us/sample - loss: 0.0397 - accuracy: 0.9931 - val_loss: 0.4241 - val_accuracy: 0.8749\n",
      "Epoch 21/40\n",
      "15000/15000 [==============================] - 0s 32us/sample - loss: 0.0380 - accuracy: 0.9939 - val_loss: 0.4334 - val_accuracy: 0.8736\n",
      "Epoch 22/40\n",
      "15000/15000 [==============================] - 0s 30us/sample - loss: 0.0366 - accuracy: 0.9941 - val_loss: 0.4382 - val_accuracy: 0.8731\n",
      "Epoch 23/40\n",
      "15000/15000 [==============================] - 0s 31us/sample - loss: 0.0355 - accuracy: 0.9943 - val_loss: 0.4393 - val_accuracy: 0.8729\n",
      "Epoch 24/40\n",
      "15000/15000 [==============================] - 1s 41us/sample - loss: 0.0340 - accuracy: 0.9945 - val_loss: 0.4478 - val_accuracy: 0.8724\n",
      "Epoch 25/40\n",
      "15000/15000 [==============================] - 0s 31us/sample - loss: 0.0326 - accuracy: 0.9955 - val_loss: 0.4562 - val_accuracy: 0.8723\n",
      "Epoch 26/40\n",
      "15000/15000 [==============================] - 1s 43us/sample - loss: 0.0317 - accuracy: 0.9955 - val_loss: 0.4612 - val_accuracy: 0.8722\n",
      "Epoch 27/40\n",
      "15000/15000 [==============================] - 1s 36us/sample - loss: 0.0300 - accuracy: 0.9958 - val_loss: 0.4681 - val_accuracy: 0.8718\n",
      "Epoch 28/40\n",
      "15000/15000 [==============================] - 1s 44us/sample - loss: 0.0293 - accuracy: 0.9959 - val_loss: 0.4821 - val_accuracy: 0.8707\n",
      "Epoch 29/40\n",
      "15000/15000 [==============================] - 1s 37us/sample - loss: 0.0278 - accuracy: 0.9964 - val_loss: 0.4785 - val_accuracy: 0.8711\n",
      "Epoch 30/40\n",
      "15000/15000 [==============================] - 1s 40us/sample - loss: 0.0269 - accuracy: 0.9966 - val_loss: 0.4873 - val_accuracy: 0.8704\n",
      "Epoch 31/40\n",
      "15000/15000 [==============================] - 1s 41us/sample - loss: 0.0258 - accuracy: 0.9969 - val_loss: 0.4916 - val_accuracy: 0.8698\n",
      "Epoch 32/40\n",
      "15000/15000 [==============================] - 0s 32us/sample - loss: 0.0249 - accuracy: 0.9968 - val_loss: 0.4967 - val_accuracy: 0.8695\n",
      "Epoch 33/40\n",
      "15000/15000 [==============================] - 1s 44us/sample - loss: 0.0240 - accuracy: 0.9969 - val_loss: 0.5039 - val_accuracy: 0.8696\n",
      "Epoch 34/40\n",
      "15000/15000 [==============================] - 1s 35us/sample - loss: 0.0233 - accuracy: 0.9970 - val_loss: 0.5089 - val_accuracy: 0.8692\n",
      "Epoch 35/40\n",
      "15000/15000 [==============================] - 1s 37us/sample - loss: 0.0224 - accuracy: 0.9973 - val_loss: 0.5174 - val_accuracy: 0.8693\n",
      "Epoch 36/40\n",
      "15000/15000 [==============================] - 1s 35us/sample - loss: 0.0213 - accuracy: 0.9977 - val_loss: 0.5265 - val_accuracy: 0.8691\n",
      "Epoch 37/40\n",
      "15000/15000 [==============================] - 0s 29us/sample - loss: 0.0205 - accuracy: 0.9976 - val_loss: 0.5289 - val_accuracy: 0.8680\n",
      "Epoch 38/40\n",
      "15000/15000 [==============================] - 0s 32us/sample - loss: 0.0195 - accuracy: 0.9977 - val_loss: 0.5365 - val_accuracy: 0.8678\n",
      "Epoch 39/40\n",
      "15000/15000 [==============================] - 0s 33us/sample - loss: 0.0184 - accuracy: 0.9980 - val_loss: 0.5565 - val_accuracy: 0.8663\n",
      "Epoch 40/40\n",
      "15000/15000 [==============================] - 1s 35us/sample - loss: 0.0175 - accuracy: 0.9979 - val_loss: 0.5540 - val_accuracy: 0.8664\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\" ,loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "x_val = train_data[:10000]\n",
    "x_train = train_data[10000:]\n",
    "y_val = train_labels[:10000]\n",
    "y_train = train_labels[10000:]\n",
    "\n",
    "fitModel = model.fit(x_train,y_train,epochs=40, batch_size=512, validation_data=(x_val,y_val), verbose=1)\n",
    "#results = model.evaluate(test_data,test_labels)\n",
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
